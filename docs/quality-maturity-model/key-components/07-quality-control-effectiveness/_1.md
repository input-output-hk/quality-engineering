### Description

-   Test engineers have minimal awareness and alignment with the tribe's Quality and Test [Strategy](../../../quality-strategy/01-getting-started.md).
-   The teams have minimal engagement with the system level **automation framework**, primarily using it as provided without active maintenance.
-   Ad-hoc system-level testing is performed, often manually, without a structured strategy or prioritization.
-   There is no, or limited, **visibility** on testing assumptions, limitations, risks, and results.

### Completeness

-   System level test coverage is sporadic, predominantly focusing on new functionalities.

### Efficiency & execution

-   Test execution is mostly manual and often inconsistent.
-   Failures are not promptly addressed.
-   Tests are rarely maintained and may be outdated quickly.

### Review processes

-   Minimal or no peer-review of test cases/scripts; limited collaboration among team members.
-   The tribe/squads have little understanding of what is not automated or tested at all.

### Results reporting

-   Test Results Reporting is mostly reactive, and when it occurs is typically only relevant to the teams with no consideration for broader project context.

### Improvement focus

-   Begin familiarizing the teams with the tribe's Quality Strategy.
-   Identify the core functionalities of the product and start planning to automate them at the system level.
-   Document the design architecture and constraints of the system-level automation framework.
-   Begin training the teams on the importance of test results reporting.
-   Introduce the concept of peer reviews among the teams (for new functionalities, user stories, acceptance criteria, test strategy and coverage, test results, etc).
