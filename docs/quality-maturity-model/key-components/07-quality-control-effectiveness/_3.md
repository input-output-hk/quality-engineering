### Description

-   Test engineers consistently align with the tribe's [Quality and Test Strategy](../../../quality-strategy/resources/02-quality-strategy-template.md) and actively apply its principles.
-   The test engineering team consistently develops, updates, and shares [System-Level Test Strategies](../../../quality-strategy/resources/03-system-level-test-strategy-template.md) for their assigned functionalities.
-   The teams actively maintain and initiate basic improvements to the system-level automation framework.
-   Comprehensive testing for new features. Some backlog remains for older, untested components or features.
-   Clear understanding and visibility of testing assumptions, limitations, active risks, and what is not automated.
-   The team systematically engages in UAT, exploratory testing, and begins dogfooding exercises to refine the release.
-   **All issues** and **risks** identified **are tracked**, prioritized, labeled with appropriate severity levels, and their trends are consistently analyzed and made accessible.
-   **New automated tests** are created or tracked for each bug fix.
-   The system-level test framework provides detailed **documentation** for execution, interpretation, and debugging, as well as guidelines for **external contributions**.
-   Performance, stress, and load testing are consistently developed and tracked as part of quality control.
-   **Customer and User Feedback** is constantly considered and integrated into the Quality Control process.

### Completeness

-   System-level coverage is balanced, covering **new, existing, core** and **critical** functionalities while increasingly addressing functional and non-functional aspects.
-   The **Quality Control** process enforces dogfooding, **UAT**, and Exploratory Testing.

### Efficiency & execution

-   Risk-based testing strategies, with scope, objectives, and resources.
-   Test failures are prioritized and addressed in a timely manner.

### Review processes

-   **Regular peer reviews of tests, at each level, is standard practice.**
-   The teams systematically identify and track areas not covered (or with poor coverage) by automation.
-   The team/tribe follows a well defined **Labelling Convention** for issues, risks, enhancements

### Results reporting

-   The tribe follows a defined process for reporting test results, with established templates and guidelines to ensure clarity, consistency, and uniformity at the **tribe and project level**.
-   Comprehensive test result reports are produced nightly and additionally for each release.

### Improvement focus

-   Promote a more consistent peer review process for both new and existing tests at the tribe level (involving both developers and test engineers).
-   Focus on refining the test automation process to cover edge cases and improve efficiency.
-   Encourage a culture of continuous improvement by regularly reviewing and updating the Quality and Test Strategy.
-   Engage in more exploratory testing and encourage feedback loops.
